import pandas as pd
import numpy as np
import re
from sentence_transformers import SentenceTransformer
from typing import List
from config import config

DATA_PATH = config["csv_path"]
PKL_PATH = config["pkl_path"]
EMBED_PATH = config["embed_path"]
MAX_TEXT_LENGTH = 500
MODEL_NAME = "BAAI/bge-base-zh"

def generate_embeddings_from_csv():
    print("ğŸš€ è½½å…¥æ¨¡å‹ä¸­...")
    # embed_model = SentenceTransformer("BAAI/bge-base-zh", device="cuda")
    embed_model = SentenceTransformer("BAAI/bge-base-zh-v1.5", device="cuda")

    print("ğŸ“„ è¯»å– CSV æ•°æ®...")
    df = pd.read_csv(DATA_PATH)
    df = df.fillna('')

    print("ğŸ§© æ„å»ºæ–‡æœ¬å­—æ®µ...")
    def card_to_text(row) -> str:
        weighted_text = (
            f"è§’è‰²åï¼š{row['name']}\n"
            f"ç®€ä»‹ï¼š{row['profile_text']}\n" * 2 +
            f"æ ¸å¿ƒç‰¹è´¨ï¼š{row['traits']}\n" * 3 +
            f"å…¸å‹éœ€æ±‚ï¼š{row['default_needs']}\n" * 2 +
            f"æƒ…æ„Ÿæ¨¡å¼ï¼š{row['emotional_patterns']}\n"
            f"å†™ä½œé£æ ¼ï¼š{row['writing_style']}\n"
            f"ä¾æ‹ç±»å‹ï¼š{row['attachment_style']}\n"
            f"æ¨èè¯­ï¼š {row['one_sentence_summary']}"
        )
        return re.sub(r'[\n\t\u3000]+', ' ', weighted_text)[:MAX_TEXT_LENGTH]

    texts = df.apply(card_to_text, axis=1).tolist()

    print("ğŸ§  ç¼–ç è¾…åŠ©å‡½æ•°åˆå§‹åŒ–...")
    def encode_field(texts: List[str]) -> List[np.ndarray]:
        arr = embed_model.encode(
            texts,
            batch_size=128,
            show_progress_bar=True,
            normalize_embeddings=True,
            convert_to_numpy=True
        )
        return [arr[i] for i in range(arr.shape[0])]

    print("ğŸ”¢ å¼€å§‹å­—æ®µç¼–ç ...")
    df["traits_vec"]    = encode_field(df["traits"].tolist())
    df["needs_vec"]     = encode_field(df["default_needs"].tolist())
    df["profile_vec"]   = encode_field(df["profile_text"].tolist())
    df["emotions_vec"]  = encode_field(df["emotional_patterns"].tolist())
    df["style_vec"]     = encode_field(df["writing_style"].tolist())
    df["one_sentence_summary_vec"] = encode_field(df["one_sentence_summary"].tolist())

    print("ğŸ” ç¼–ç å…¨æ–‡åµŒå…¥ï¼ˆç”¨äº faiss æ£€ç´¢ï¼‰...")
    full_embeddings = embed_model.encode(
        texts,
        batch_size=128,
        show_progress_bar=True,
        normalize_embeddings=True,
        convert_to_numpy=True
    )

    print("ğŸ’¾ æ­£åœ¨ä¿å­˜å‘é‡...")
    df.to_pickle(PKL_PATH)
    np.save(EMBED_PATH, full_embeddings)

    print("âœ… ä¿å­˜å®Œæˆï¼š")
    print(f" - å­—æ®µå‘é‡ â†’ {PKL_PATH}")
    print(f" - æ£€ç´¢åµŒå…¥ â†’ {EMBED_PATH}")